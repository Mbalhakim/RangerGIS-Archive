{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, Dense, GRU, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model definition\n",
    "def create_crnn(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Reshape for RNN layers\n",
    "    x = Reshape((-1, x.shape[-1]))(x)\n",
    "\n",
    "    # Recurrent layers\n",
    "    x = GRU(128, return_sequences=True)(x)\n",
    "    x = GRU(128, return_sequences=True)(x)\n",
    "\n",
    "    # Fully connected layer\n",
    "    outputs = Dense(num_classes + 1, activation='softmax')(x)\n",
    "\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define character set (modify if needed)\n",
    "CHARACTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789()\"\n",
    "\n",
    "def encode_label(label):\n",
    "    return [CHARACTERS.index(char) for char in label]\n",
    "\n",
    "def load_data(mapping_file, image_size):\n",
    "    images, labels = [], []\n",
    "    with open(mapping_file, 'r') as file:\n",
    "        for line in file:\n",
    "            image_path, label = line.strip().split()\n",
    "            # Load and preprocess image\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, image_size) / 255.0\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            images.append(image)\n",
    "            labels.append(encode_label(label))\n",
    "    return np.array(images), labels\n",
    "\n",
    "# Example usage\n",
    "mapping_file = \"dataset/labels.txt\"\n",
    "image_size = (128, 32)  # Resize all images to 128x32\n",
    "X, y = load_data(mapping_file, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.backend import ctc_batch_cost\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'display'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(CHARACTERS)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create the CRNN model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_crnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mctc_loss\u001b[39m(y_true, y_pred):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Get the batch size\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(y_pred)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m, in \u001b[0;36mcreate_crnn\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(num_classes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs, outputs)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'display'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = (32, 128, 1)  # Image dimensions (height, width, channels)\n",
    "num_classes = len(CHARACTERS)\n",
    "\n",
    "# Create the CRNN model\n",
    "model = create_crnn(input_shape, num_classes)\n",
    "\n",
    "def ctc_loss(y_true, y_pred):\n",
    "    # Get the batch size\n",
    "    batch_size = tf.shape(y_pred)[0]\n",
    "    # Predicted sequence lengths (based on model output width)\n",
    "    input_length = tf.fill([batch_size], tf.shape(y_pred)[1])\n",
    "    # Actual label lengths (non-padded parts of y_true)\n",
    "    label_length = tf.reduce_sum(tf.cast(tf.not_equal(y_true, -1), tf.int32), axis=1)\n",
    "    return ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=ctc_loss)\n",
    "\n",
    "# Convert labels to categorical and pad them\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "y_padded = pad_sequences(y, padding='post', value=-1)  # Use -1 as padding value\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y_padded, batch_size=32, epochs=50, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
